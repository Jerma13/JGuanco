---
title: "RWorksheet_5.Rmd"
author: "Jermalyn Guanco"
output: pdf_document
---

```{r 1. Create a data frame for the table below. Show your solution.}
#a. Compute the descriptive statistics using different packages (Hmisc and pastecs).Write the codes and its result.

library(Hmisc)
library(pastecs)
library(dplyr)

desStat <- data.frame(
 Category = c("A", "B", "C", "A", "B", "C", "A", "B", "C"),
 Score = c(50, 70, 60, 55, 75, 65, 53, 73, 63)
)

hmiscStat <- describe(desStat$Score)
print(hmiscStat)

pastecsStat <- round(fivenum(desStat$Score), 2)
names(pastecsStat) <- c("Min", "Q1", "Median", "Q3", "Max")
print(pastecsStat)
```

```{r 2. The Department of Agriculture was studying the effects of several levels of a fertilizer on the growth of a plant. For some analyses, it might be useful to convert the fertilizer levels to an ordered factor.}

fertilizerLevels <- c(10,10,10,20,20,50,10,20,10,50,20,50,20,10)
FertOrdered <- as.ordered(fertilizerLevels)
print(FertOrdered)
```

```{r 3. Abdul Hassan, president of Floor Coverings Unlimited, has asked you to study the exercise levels undertaken by 10 subjects were “l”, “n”, “n”, “i”, “l” , “l”, “n”,“n”, “i”, “l” ; n=none, l=light, i=intense}

exerciseLevels <- data.frame(
  subject = c(1, 2, 3, 4, 5, 6, 7, 8, 9, 10),
  exercise = c("n", "l", "n", "i", "l", "l", "n", "n", "i", "l")
)
exerciseLevels$subject
exerciseLevels$exercise

exerciseLevels[,1] 
exerciseLevels[,2] 
```

```{r 4. Sample of 30 tax accountants from all the states and territories of Australia and their individual state of origin is specified by a character vector of state mnemonics as: }

state <- c("tas", "sa", "qld", "nsw", "nsw", "nt", "wa", "wa", "qld",
"vic", "nsw", "vic", "qld", "qld", "sa", "tas", "sa", "nt",
"wa", "vic", "qld", "nsw", "nsw", "wa", "sa", "act", "nsw",
"vic", "vic", "act")

state_factor <- factor(state)
stateFactorOrder <- factor(state, levels = c("act", "nsw", "nt", "qld", "sa", "tas", "vic", "wa"))
state_factor
```

```{r 5. From #4 - continuation:}

incomes <- c(60, 49, 40, 61, 64, 60, 59, 54,
62, 69, 70, 42, 56, 61, 61, 61, 58, 51, 48,
65, 49, 49, 41, 48, 52, 46, 59, 46, 58, 43)

income_means <- tapply(incomes, state_factor, mean)
income_means

#b. Copy the results and interpret.
     act      nsw       nt      qld       sa      tas      vic 
44.50000 57.33333 55.50000 53.60000 55.00000 60.50000 56.00000 
      wa 
52.25000 
```
```{r 6. Calculate the standard errors of the state income means (refer again to number 3}

stdError <- function(x) sqrt(var(x)/length(x))
incster <- tapply(incomes, state_factor, stdError)
incster
```
```{r 7. Use the titanic dataset.}

data(Titanic)
survivors <- Titanic[Titanic$survived == 1, ]
nonSurvivors <- Titanic[Titanic$survived == 0, ]
nrow(survivors)
nrow(nonSurvivors)
```

```{r 8. The data sets are about the breast cancer Wisconsin. The samples arrive periodically as Dr. Wolberg reports his clinical cases. The database therefore reflects this chronologihttps://drive.google.com/file/d/16MFLoehCgx2MJuNSAuB2CsBy6eDIIru/view?usp=drive_link) }

#The dataset provided is all about Breast Cancer Wisconsin, it contains information about breast cancer samples. The dataset is to assist in the diagnosis of breast cancer based on various measurements and characteristics of the tumor cells. The dataset includes numerical and categorical features related to the cell nuclei, such as radius, perimeter, concavity, and texture, as well as other clinical information like diagnosis and ID number.
```

```{r d. Compute the descriptive statistics using different packages. Find the values of: }
# d.1 Standard error of the mean for clump thickness.
#d.2 Coefficient of variability for Marginal Adhesion.
#d.3 Number of null values of Bare Nuclei.
#d.4 Mean and standard deviation for Bland Chromatin
#d.5 Confidence interval of the mean for Uniformity of Cell Shape

library(tidyverse)
library(psych)

data <- read.csv("breastcancer_wisconsin.csv")

clump_thickness <- data %>% select(clump_thickness) %>% as.numeric()
se_mean_clump <- sd(clump_thickness) / sqrt(length(clump_thickness))
cat("The standard error of the mean for clump thickness is:", se_mean_clump, "\n")

marginal_adhesion <- data %>% select(MarginalAdhesion) %>% as.numeric()
cv_marginal <- sd(marginal_adhesion) / mean(marginal_adhesion) * 100 %>% round(2)
cat("The coefficient of variability for Marginal Adhesion is:", cv_marginal, "%\n")

BareNuclei <- data %>% select(Bare.Nuclei) %>% na.omit() %>% summarize(n = length(Bare.Nuclei)) %>% print() 
cat("The number of null values of Bare Nuclei is:", BareNuclei$n, "\n")

BlandChromatin <- data %>% select(BlandChromatin) %>% as.numeric() %>% summarize(mean = mean(.), sd = sd(.), n = length(.)) %>% print() 
cat("The mean for Bland Chromatin is:", BlandChromatin$mean, "\n") 
cat("The standard deviation for Bland Chromatin is:", BlandChromatin$sd, "\n")

UniformityOfCellShape <- data %>% select(UniformityOfCellShape) %>% as.numeric()
ci_uniformity <- ci.normal(mean = UniformityOfCellShape, sd = sd(UniformityOfCellShape), conf.level = 0.95) 
cat("The confidence interval of the mean for Uniformity of Cell Shape is:", ci_uniformity, "\n")
```

```{r 9. Export the data abalone to the Microsoft excel file. Copy the codes.}

install.packages("AppliedPredictiveModeling")
library("AppliedPredictiveModeling")
view(abalone)
head(abalone)
summary(abalone)